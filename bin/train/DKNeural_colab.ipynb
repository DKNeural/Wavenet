{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC3XkMetGWtK"
      },
      "source": [
        "# Neural Amp Modeler (\"Easy Mode\" Trainer)\n",
        "This notebook allows you to train a neural amp model based on a pair of input/output WAV files that you have of the amp you want to model.\n",
        "\n",
        "**Note**:\n",
        "This notebook is meant to be used on [Google Colab](https://colab.research.google.com/github/sdatkinson/neural-amp-modeler/blob/main/bin/train/easy_colab.ipynb).\n",
        "\n",
        "ðŸ”¶**Before you run**ðŸ”¶\n",
        "\n",
        "Make sure to get a GPU! (From the upper-left menu, click Runtime->Change runtime type->Select \"GPU\" from the \"Hardware accelerator dropdown menu)\n",
        "\n",
        "âš **Warning**âš \n",
        "\n",
        "Google Colab GPU instances only last for 12 hours.\n",
        "Plan your training accordingly!\n",
        "\n",
        "## Steps:\n",
        "1. Get your data\n",
        "2. Installation\n",
        "3. Enter metadata\n",
        "4. Train!\n",
        "5. Check the results and download your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CQleTk7GJV8"
      },
      "source": [
        "## Step 1: Get data\n",
        "We're gonna need data. \"Easy mode\" takes out a lot of the guesswork.\n",
        "\n",
        "### Step 1.1: Download the capture signal\n",
        "\"Easy mode\" uses a pre-crafted \"capture signal\".\n",
        "Download it here: [v1_1_1.wav](https://drive.google.com/file/d/1v2xFXeQ9W2Ks05XrqsMCs2viQcKPAwBk/view?usp=share_link).\n",
        "\n",
        "### Step 1.2 Reamp your gear\n",
        "Then reamp the gear you want to model using it. Save that reamp as \"output.wav\".\n",
        "**Please use 48kHz, 24-bit, mono.** We'll support other sample rates etc in the future; sit tight!\n",
        "\n",
        "### Step 1.3: upload!\n",
        "Upload the input (DI) and output (amped) files you want to use by clicking the Folder icon on the left â¬… and then clicking the upload icon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g_4GtFuGlO8"
      },
      "source": [
        "## Step 2: Installation\n",
        "Install `nam` into this Colab instance by running the next cell (hover over and click the play button that appears in the upper-left corner):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYQIpWr5EYRb"
      },
      "outputs": [],
      "source": [
        "!pip install wavenet-training\n",
        "\n",
        "from nam.train.colab import run as _run\n",
        "run = _run\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tRCyI_YjZjj"
      },
      "source": [
        "## Step 3: Enter metadata\n",
        "Tell us about what you're modeling!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zrXbQY7vjZjk"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from nam.models.metadata import GearType, ToneType, UserMetadata\n",
        "#@markdown NAM name\n",
        "name = \"My model\" #@param {type:\"string\"}\n",
        "#@markdown Modeled by:\n",
        "modeled_by = \"Your name\" #@param {type:\"string\"}\n",
        "#@markdown Gear make:\n",
        "gear_make = \"GearCo\" #@param {type:\"string\"}\n",
        "#@markdown Gear model:\n",
        "gear_model = \"GearAmp\" #@param {type:\"string\"}\n",
        "#@markdown Gear type:\n",
        "# This needs to be a literal. You need to change it by hand if you change the enum!\n",
        "gear_type = \"Pick from: amp, pedal, amp_cab, amp_pedal_cab, preamp, studio\" #@param {type:\"string\"}\n",
        "#@markdown Tone type:\n",
        "tone_type = \"Pick from: clean, overdrive, crunch, hi_gain, fuzz\" #@param {type:\"string\"}\n",
        "\n",
        "def _verbose_enum(E, val):\n",
        "    try:\n",
        "        return E(val)\n",
        "    except ValueError as e:\n",
        "        raise ValueError(\n",
        "            str(e) \n",
        "            + \"\\nValid choices are: \" \n",
        "            + \", \".join(list(x.value for x in E))\n",
        "        )\n",
        "\n",
        "user_metadata = UserMetadata(\n",
        "    name=name, \n",
        "    modeled_by=modeled_by, \n",
        "    gear_make=gear_make, \n",
        "    gear_model=gear_model, \n",
        "    gear_type=_verbose_enum(GearType, gear_type.lower()), \n",
        "    tone_type=_verbose_enum(ToneType, tone_type.lower())\n",
        ")\n",
        "run = partial(_run, user_metadata=user_metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVkBZg3-jZjl"
      },
      "source": [
        "## Step 4: Train!\n",
        "Here we go!\n",
        "\n",
        "ðŸ•™Training will go through 100 epochs and take just over 10 minutes.ðŸ•™\n",
        "\n",
        "If you want a better model, you can try training for more \"**epochs**\"--just put in a \n",
        "different number before hitting go!\n",
        "\n",
        "\"**architecture**\" selects from several presets for the size of the network. This trades off\n",
        "modeling quality for how expensive the resulting model will be to run.\n",
        "\n",
        "   \"**lite**\" models will run approximately **1.5 times** faster than \"**standard**\".\n",
        "\n",
        "   \"**feather**\" models will run more than **2 times** faster than \"**standard**\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOzo3NxqjZjl"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir /content/lightning_logs\n",
        "run(\n",
        "    epochs=100,\n",
        "    architecture=\"standard\"  # standard, lite, feather\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823KJ_L0Rchp"
      },
      "source": [
        "## Step 5: Check the results and download your model\n",
        "We're done!\n",
        "\n",
        "Have a look at the plot above to see how your model compares to the real gear you're modeling.\n",
        "Hopefully it looks good!\n",
        "Go to the file browser on the left panel â¬… and download `model.nam` from the `exported_model` directory (you may need to hit the refresh button).\n",
        "\n",
        "Additionally, if you want to continue to train this model later you can download the lightning model artifacts from `lightning_logs`. If not, that's fine too.\n",
        "\n",
        "# ðŸŽ¸ **ENJOY!** ðŸŽ¸"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nam",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "920df60c69944ba95f8c12adb41fedfdc8090c370a20d39253c7705973dd37db"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
